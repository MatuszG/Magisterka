{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49378c11-ef2a-4887-b1c2-83abd73ce5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence\n",
      "0   <|startoftext|>Title: Sharptalon's Claw Descri...\n",
      "1   <|startoftext|>Title: Riverpaw Gnoll Bounty De...\n",
      "2   <|startoftext|>Title: Give Gerard a Drink Desc...\n",
      "3   <|startoftext|>Title: Ursangous' Paw Descripti...\n",
      "4   <|startoftext|>Title: Shadumbra's Head Descrip...\n",
      "..                                                ...\n",
      "95  <|startoftext|>Title: Securing the Lines Descr...\n",
      "96  <|startoftext|>Title: Rescue OOX-09/HL! Descri...\n",
      "97  <|startoftext|>Title: Conscript of the Horde D...\n",
      "98  <|startoftext|>Title: Plainstrider Menace Desc...\n",
      "99  <|startoftext|>Title: The Zhevra Description: ...\n",
      "\n",
      "[100 rows x 1 columns]\n",
      "90\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForCausalLM, AutoTokenizer\n",
    "output_path = 'Models/gpt2-large/wow-test'\n",
    "texts = pd.read_csv('data_wow.csv', nrows=100)\n",
    "# texts = pd.read_csv('data_wow.csv')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_name = \"gpt2-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.labels = []\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []        \n",
    "        for sentence in txt_list['sentence']:\n",
    "            encodings_dict = tokenizer(sentence, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    def __len__(self): return len(self.input_ids)\n",
    "    def __getitem__(self, idx): return self.input_ids[idx], self.attn_masks[idx]\n",
    "\n",
    "max_length = max([len(tokenizer.encode(sentence)) for sentence in texts['sentence']])\n",
    "dataset = TextDataset(texts, tokenizer, max_length=max_length)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "print(texts)\n",
    "print(train_size)\n",
    "print(len(dataset) - train_size)\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"]='gpt-neo-125M'\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "os.environ[\"WANDB_NAME\"]=\"gpt-neo-wow\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"b689f7c91f1ec7520fa8da927f175f1efd587181\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe14f7b-ff65-413a-bd83-51e9a9cfaa4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     # model = AutoModelForCausalLM.from_pretrained(os.path.join(output_path, 'results')).cuda()\n",
    "#     model = AutoModelForCausalLM.from_pretrained(os.path.join(output_path, 'results', 'checkpoint-1825')).cuda()\n",
    "#     print('saved')\n",
    "# except:\n",
    "#     model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "#     print('downloaded')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e299bf-2275-41ac-bdb0-725dacbf6a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def decode(input_ids_tensor):\n",
    "    token_ids_list = input_ids_tensor.tolist()\n",
    "    # Decode the token IDs into text\n",
    "    return tokenizer.decode(token_ids_list, skip_special_tokens=True)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "def decodeLogits(logits):\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    logits_tensor = torch.tensor(logits, dtype=torch.float)\n",
    "    probabilities = F.softmax(logits_tensor, dim=-1)\n",
    "\n",
    "    # Get the token IDs (the indices of the highest probabilities)\n",
    "    token_ids = torch.argmax(probabilities, dim=-1)\n",
    "    return tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "\n",
    "# !pip install bert-score\n",
    "import bert_score\n",
    "\n",
    "def calculate_bertscore(predictions, references, lang='en'):\n",
    "    # Calculate BERTScore\n",
    "    # P, R, F1 = bert_score.score(predictions, references, lang=lang)\n",
    "    P, R, F1 = bert_score.score(predictions, references, lang=lang, model_type='distilbert-base-uncased', verbose=True)\n",
    "    \n",
    "    # Compute average scores\n",
    "    avg_precision = P.mean().item()\n",
    "    avg_recall = R.mean().item()\n",
    "    avg_f1 = F1.mean().item()\n",
    "    \n",
    "    return {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1': avg_f1\n",
    "    }\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def compute_rouge_in_chunks(candidates, references, chunk_size=100):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    results = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    \n",
    "    for i in range(0, len(candidates), chunk_size):\n",
    "        chunk_candidates = candidates[i:i + chunk_size]\n",
    "        chunk_references = references[i:i + chunk_size]\n",
    "        \n",
    "        for c, r in zip(chunk_candidates, chunk_references):\n",
    "            decoded_r = decode(r)\n",
    "            decoded_c = decodeLogits(c)\n",
    "            scores = scorer.score(decoded_r, decoded_c)\n",
    "            print(scores)\n",
    "            for key in results.keys():\n",
    "                results[key].append(scores[key].fmeasure)\n",
    "\n",
    "    average_scores = {key: sum(scores) / len(scores) for key, scores in results.items()}\n",
    "    return average_scores\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import wandb\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    references = pred.label_ids\n",
    "    print(\"references\")\n",
    "    print(len(references))\n",
    "    print(len(references[1]))\n",
    "    print(references)\n",
    "    generated_texts = pred.predictions\n",
    "    print(\"generated_texts\")\n",
    "    print(len(generated_texts))\n",
    "    print(len(generated_texts[1]))\n",
    "    print(generated_texts)\n",
    "    bleu_scores = []\n",
    "    bert_scores = []\n",
    "    for reference, generated_text in zip(references, generated_texts):\n",
    "        reference_text = decode(reference)\n",
    "        predicted_text = decodeLogits(generated_text)\n",
    "        bert_score = calculate_bertscore([predicted_text], [reference_text])\n",
    "        bert_scores.append(bert_score)\n",
    "        bleu_score = sentence_bleu([reference_text], predicted_text)\n",
    "        bleu_scores.append(bleu_score)\n",
    "        \n",
    "    avg_precision = sum(score['precision'] for score in bert_scores) / len(bert_scores)\n",
    "    avg_recall = sum(score['recall'] for score in bert_scores) / len(bert_scores)\n",
    "    avg_f1 = sum(score['f1'] for score in bert_scores) / len(bert_scores)\n",
    "    rouge = compute_rouge_in_chunks(generated_texts, references)\n",
    "\n",
    "    metric = {\n",
    "        'bleu': sum(bleu_scores) / len(bleu_scores),\n",
    "        'rouge1': rouge['rouge1'],\n",
    "        'rouge2': rouge['rouge2'],\n",
    "        'rougeL': rouge['rougeL'],\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1': avg_f1,\n",
    "    }\n",
    "    # wandb.log(metric)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f23b30-ae77-4891-9ad7-a3bd1273f31d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-02 18:38:21,841] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgarbacik-mateusz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/wandb/run-20240902_183823-iuchg26g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/garbacik-mateusz/gpt-neo-125M/runs/iuchg26g' target=\"_blank\">Models/gpt2-large/wow-test/results</a></strong> to <a href='https://wandb.ai/garbacik-mateusz/gpt-neo-125M' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/garbacik-mateusz/gpt-neo-125M' target=\"_blank\">https://wandb.ai/garbacik-mateusz/gpt-neo-125M</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/garbacik-mateusz/gpt-neo-125M/runs/iuchg26g' target=\"_blank\">https://wandb.ai/garbacik-mateusz/gpt-neo-125M/runs/iuchg26g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 03:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.872700</td>\n",
       "      <td>2.100692</td>\n",
       "      <td>0.532010</td>\n",
       "      <td>0.475725</td>\n",
       "      <td>0.122061</td>\n",
       "      <td>0.366159</td>\n",
       "      <td>0.811699</td>\n",
       "      <td>0.822574</td>\n",
       "      <td>0.817064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "references\n",
      "10\n",
      "152\n",
      "[[50257 19160    25 ... 50258 50258 50258]\n",
      " [50257 19160    25 ... 50258 50258 50258]\n",
      " [50257 19160    25 ... 50258 50258 50258]\n",
      " ...\n",
      " [50257 19160    25 ... 50258 50258 50258]\n",
      " [50257 19160    25 ... 50258 50258 50258]\n",
      " [50257 19160    25 ... 50258 50258 50258]]\n",
      "generated_texts\n",
      "10\n",
      "152\n",
      "[[[ 3.8504245   9.532602    7.399828   ...  3.137138    0.15738165\n",
      "    1.9968677 ]\n",
      "  [ 1.1993176   1.3537091  -1.1069249  ... -0.96102345  0.21271294\n",
      "    5.9031916 ]\n",
      "  [ 1.9392525  -0.5196158  -2.0593638  ...  2.867333    1.1849325\n",
      "    2.430071  ]\n",
      "  ...\n",
      "  [ 0.44632345  1.8249662  -0.2775296  ... -2.6185632   0.678132\n",
      "   22.50478   ]\n",
      "  [ 0.43875572  1.821381   -0.27259457 ... -2.625413    0.6819918\n",
      "   22.501282  ]\n",
      "  [ 0.43064559  1.8217617  -0.2738299  ... -2.6206179   0.6788767\n",
      "   22.498539  ]]\n",
      "\n",
      " [[ 3.8504245   9.532602    7.399828   ...  3.137138    0.15738165\n",
      "    1.9968677 ]\n",
      "  [ 1.1993176   1.3537091  -1.1069249  ... -0.96102345  0.21271294\n",
      "    5.9031916 ]\n",
      "  [ 1.9392525  -0.5196158  -2.0593638  ...  2.867333    1.1849325\n",
      "    2.430071  ]\n",
      "  ...\n",
      "  [ 0.45523608  1.749283   -0.29010832 ... -2.7543721   0.7336734\n",
      "   22.504108  ]\n",
      "  [ 0.4432599   1.7426679  -0.27844003 ... -2.7640402   0.74014276\n",
      "   22.505083  ]\n",
      "  [ 0.43557873  1.7409221  -0.27762893 ... -2.7535992   0.7382468\n",
      "   22.504217  ]]\n",
      "\n",
      " [[ 3.8504245   9.532602    7.399828   ...  3.137138    0.15738165\n",
      "    1.9968677 ]\n",
      "  [ 1.1993176   1.3537091  -1.1069249  ... -0.96102345  0.21271294\n",
      "    5.9031916 ]\n",
      "  [ 1.9392525  -0.5196158  -2.0593638  ...  2.867333    1.1849325\n",
      "    2.430071  ]\n",
      "  ...\n",
      "  [ 0.59655243  1.8348105  -0.10824722 ... -2.3678224   0.7242657\n",
      "   22.503542  ]\n",
      "  [ 0.5976525   1.844827   -0.09476417 ... -2.3722076   0.7278812\n",
      "   22.50493   ]\n",
      "  [ 0.59618276  1.8440093  -0.10476884 ... -2.3648102   0.72334266\n",
      "   22.506786  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.8504245   9.532602    7.399828   ...  3.137138    0.15738165\n",
      "    1.9968677 ]\n",
      "  [ 1.1993176   1.3537091  -1.1069249  ... -0.96102345  0.21271294\n",
      "    5.9031916 ]\n",
      "  [ 1.9392525  -0.5196158  -2.0593638  ...  2.867333    1.1849325\n",
      "    2.430071  ]\n",
      "  ...\n",
      "  [ 0.63058954  1.8898617  -0.19528757 ... -2.4824367   0.6595341\n",
      "   22.494705  ]\n",
      "  [ 0.6207552   1.8883492  -0.1886897  ... -2.4867754   0.6614181\n",
      "   22.493246  ]\n",
      "  [ 0.6215584   1.8899474  -0.18950185 ... -2.4829364   0.6595234\n",
      "   22.494865  ]]\n",
      "\n",
      " [[ 3.8504245   9.532602    7.399828   ...  3.137138    0.15738165\n",
      "    1.9968677 ]\n",
      "  [ 1.1993176   1.3537091  -1.1069249  ... -0.96102345  0.21271294\n",
      "    5.9031916 ]\n",
      "  [ 1.9392525  -0.5196158  -2.0593638  ...  2.867333    1.1849325\n",
      "    2.430071  ]\n",
      "  ...\n",
      "  [ 0.7198279   1.9288062  -0.21260998 ... -2.732357    0.7166449\n",
      "   22.633198  ]\n",
      "  [ 0.71502614  1.9298885  -0.20380028 ... -2.7385607   0.7191584\n",
      "   22.632519  ]\n",
      "  [ 0.7178455   1.9326109  -0.21300068 ... -2.7393386   0.7178251\n",
      "   22.6335    ]]\n",
      "\n",
      " [[ 3.8504245   9.532602    7.399828   ...  3.137138    0.15738165\n",
      "    1.9968677 ]\n",
      "  [ 1.1993176   1.3537091  -1.1069249  ... -0.96102345  0.21271294\n",
      "    5.9031916 ]\n",
      "  [ 1.9392525  -0.5196158  -2.0593638  ...  2.867333    1.1849325\n",
      "    2.430071  ]\n",
      "  ...\n",
      "  [ 0.40830633  1.7687228  -0.3737208  ... -2.5038848   0.6580445\n",
      "   22.439508  ]\n",
      "  [ 0.40535137  1.7721002  -0.35789058 ... -2.508936    0.6587993\n",
      "   22.438635  ]\n",
      "  [ 0.39719898  1.7687012  -0.36464375 ... -2.5027802   0.6591812\n",
      "   22.438496  ]]]\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b3cf7e4036415fb3f573c08d9d9eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b582f0ab84cd4f23a929b37dfd0a84fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 22.66 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f68573f70b413faef3856d962b399d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee1a09ed7bc48cf85ddb380e69f705e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.72 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f9ea1a38a24ac5abfea1cab35b4bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a19fccbf194430a959f837c5608a30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 35.35 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bebb65c9da4086ad4741390006efe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2826883dcf284b83983a43bbb2ac9176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.07 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196ec61cdc024e5b9959d94ebeaac57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957534ab84284e649a5dde62c29a1abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.17 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481b701228f3472aae2f19a68c7ebaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad06cf7f1f55415b95d16ffb11d01c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 34.06 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4111b7bf0b4241a1fbff3795276b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8638b92337b04cbd852ec02f0fc72b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 33.76 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf03b50d30f44636995e2654fd251954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0899e57da0354c519dec866675a26681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.19 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae496fe5cda42a891c225d014d8336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fb20a5e42b445f9b164921815e6db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.28 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f6f3d92322402da5749128b3d11345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873f3db7f8044650bb4f9c3f1c1cd261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 34.93 sentences/sec\n",
      "{'rouge1': Score(precision=0.5211267605633803, recall=0.5068493150684932, fmeasure=0.513888888888889), 'rouge2': Score(precision=0.12857142857142856, recall=0.125, fmeasure=0.1267605633802817), 'rougeL': Score(precision=0.38028169014084506, recall=0.3698630136986301, fmeasure=0.375)}\n",
      "{'rouge1': Score(precision=0.4931506849315068, recall=0.48, fmeasure=0.48648648648648646), 'rouge2': Score(precision=0.1388888888888889, recall=0.13513513513513514, fmeasure=0.136986301369863), 'rougeL': Score(precision=0.4246575342465753, recall=0.41333333333333333, fmeasure=0.4189189189189189)}\n",
      "{'rouge1': Score(precision=0.5, recall=0.5, fmeasure=0.5), 'rouge2': Score(precision=0.15555555555555556, recall=0.15555555555555556, fmeasure=0.15555555555555556), 'rougeL': Score(precision=0.3695652173913043, recall=0.3695652173913043, fmeasure=0.36956521739130427)}\n",
      "{'rouge1': Score(precision=0.45054945054945056, recall=0.4659090909090909, fmeasure=0.45810055865921784), 'rouge2': Score(precision=0.07777777777777778, recall=0.08045977011494253, fmeasure=0.0790960451977401), 'rougeL': Score(precision=0.31868131868131866, recall=0.32954545454545453, fmeasure=0.324022346368715)}\n",
      "{'rouge1': Score(precision=0.5060240963855421, recall=0.47191011235955055, fmeasure=0.4883720930232558), 'rouge2': Score(precision=0.17073170731707318, recall=0.1590909090909091, fmeasure=0.16470588235294117), 'rougeL': Score(precision=0.39759036144578314, recall=0.3707865168539326, fmeasure=0.3837209302325581)}\n",
      "{'rouge1': Score(precision=0.4722222222222222, recall=0.5, fmeasure=0.4857142857142857), 'rouge2': Score(precision=0.08450704225352113, recall=0.08955223880597014, fmeasure=0.08695652173913045), 'rougeL': Score(precision=0.375, recall=0.39705882352941174, fmeasure=0.38571428571428573)}\n",
      "{'rouge1': Score(precision=0.5396825396825397, recall=0.5074626865671642, fmeasure=0.5230769230769231), 'rouge2': Score(precision=0.16129032258064516, recall=0.15151515151515152, fmeasure=0.15625), 'rougeL': Score(precision=0.3968253968253968, recall=0.373134328358209, fmeasure=0.38461538461538464)}\n",
      "{'rouge1': Score(precision=0.4090909090909091, recall=0.4186046511627907, fmeasure=0.4137931034482759), 'rouge2': Score(precision=0.09195402298850575, recall=0.09411764705882353, fmeasure=0.09302325581395349), 'rougeL': Score(precision=0.32954545454545453, recall=0.3372093023255814, fmeasure=0.3333333333333333)}\n",
      "{'rouge1': Score(precision=0.4642857142857143, recall=0.4148936170212766, fmeasure=0.43820224719101125), 'rouge2': Score(precision=0.08433734939759036, recall=0.07526881720430108, fmeasure=0.07954545454545454), 'rougeL': Score(precision=0.3333333333333333, recall=0.2978723404255319, fmeasure=0.3146067415730337)}\n",
      "{'rouge1': Score(precision=0.4461538461538462, recall=0.453125, fmeasure=0.4496124031007752), 'rouge2': Score(precision=0.140625, recall=0.14285714285714285, fmeasure=0.14173228346456693), 'rougeL': Score(precision=0.36923076923076925, recall=0.375, fmeasure=0.37209302325581395)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=2.93660302956899, metrics={'train_runtime': 200.5942, 'train_samples_per_second': 0.449, 'train_steps_per_second': 0.09, 'total_flos': 58144684032000.0, 'train_loss': 2.93660302956899, 'epoch': 1.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        print(logs)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=os.path.join(output_path, 'results'),\n",
    "                                  num_train_epochs=1,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  overwrite_output_dir=True,\n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=5, #56\n",
    "                                  per_device_eval_batch_size=5,\n",
    "                                  warmup_steps=10,\n",
    "                                  logging_steps=1,\n",
    "                                  weight_decay=0.05,\n",
    "                                  logging_dir=os.path.join(output_path, 'logs'),\n",
    "                                  report_to = 'wandb')\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "        args=training_args,\n",
    "        train_dataset = train_dataset, \n",
    "        eval_dataset = val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "        data_collator = lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                      'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                      'labels': torch.stack([f[0] for f in data])})\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "# model.save_pretrained(os.path.join(output_path, 'results'))\n",
    "# tokenizer.save_pretrained(os.path.join(output_path, 'results'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3638fcf-78b1-4fda-a000-e1f88e7c1528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3adc1c4c6864c20975aa8d09b738548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5b86e74af542379bc9b17344e99aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 26.23 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c881c44a9e9c4f02a62d88b6bb53b8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858e02b32bd14541afe3cb90a575919c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.48 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafd761bb67544c3bc59093c56e993ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572a5c67f4f541b091d5be5317cf537a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.91 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6322f09918004e42bc246aa640f5ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a245a8a3264b7593311eb82fb2acd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.42 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b0409890834aa283c40e776bf3c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3d63dccc9f4c4a93e8bfb1aef3d0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.39 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332aca09e2794f619c6a78a9ddb338de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f6e955f73c4223945c46f3a985b912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 34.40 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eafc84343964ad8b9e60df2b18bef68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12c5eb77ef447ee8130b95b783aa84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 35.59 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf2d06442f3478f86ef80e85eb76892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013ac251c30b493f84d5276309856f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.71 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3711c09d7f3c4876962fc26bef77af53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b377e23e18c046aea6afa718c693c750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.73 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a4ee1d892a44f1890bfe30873aabbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a4406aa789451297cbcb3d104d13e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 36.00 sentences/sec\n",
      "{'rouge1': Score(precision=0.5211267605633803, recall=0.5068493150684932, fmeasure=0.513888888888889), 'rouge2': Score(precision=0.12857142857142856, recall=0.125, fmeasure=0.1267605633802817), 'rougeL': Score(precision=0.38028169014084506, recall=0.3698630136986301, fmeasure=0.375)}\n",
      "{'rouge1': Score(precision=0.4931506849315068, recall=0.48, fmeasure=0.48648648648648646), 'rouge2': Score(precision=0.1388888888888889, recall=0.13513513513513514, fmeasure=0.136986301369863), 'rougeL': Score(precision=0.4246575342465753, recall=0.41333333333333333, fmeasure=0.4189189189189189)}\n",
      "{'rouge1': Score(precision=0.5, recall=0.5, fmeasure=0.5), 'rouge2': Score(precision=0.15555555555555556, recall=0.15555555555555556, fmeasure=0.15555555555555556), 'rougeL': Score(precision=0.3695652173913043, recall=0.3695652173913043, fmeasure=0.36956521739130427)}\n",
      "{'rouge1': Score(precision=0.45054945054945056, recall=0.4659090909090909, fmeasure=0.45810055865921784), 'rouge2': Score(precision=0.07777777777777778, recall=0.08045977011494253, fmeasure=0.0790960451977401), 'rougeL': Score(precision=0.31868131868131866, recall=0.32954545454545453, fmeasure=0.324022346368715)}\n",
      "{'rouge1': Score(precision=0.5060240963855421, recall=0.47191011235955055, fmeasure=0.4883720930232558), 'rouge2': Score(precision=0.17073170731707318, recall=0.1590909090909091, fmeasure=0.16470588235294117), 'rougeL': Score(precision=0.39759036144578314, recall=0.3707865168539326, fmeasure=0.3837209302325581)}\n",
      "{'rouge1': Score(precision=0.4722222222222222, recall=0.5, fmeasure=0.4857142857142857), 'rouge2': Score(precision=0.08450704225352113, recall=0.08955223880597014, fmeasure=0.08695652173913045), 'rougeL': Score(precision=0.375, recall=0.39705882352941174, fmeasure=0.38571428571428573)}\n",
      "{'rouge1': Score(precision=0.5396825396825397, recall=0.5074626865671642, fmeasure=0.5230769230769231), 'rouge2': Score(precision=0.16129032258064516, recall=0.15151515151515152, fmeasure=0.15625), 'rougeL': Score(precision=0.3968253968253968, recall=0.373134328358209, fmeasure=0.38461538461538464)}\n",
      "{'rouge1': Score(precision=0.4090909090909091, recall=0.4186046511627907, fmeasure=0.4137931034482759), 'rouge2': Score(precision=0.09195402298850575, recall=0.09411764705882353, fmeasure=0.09302325581395349), 'rougeL': Score(precision=0.32954545454545453, recall=0.3372093023255814, fmeasure=0.3333333333333333)}\n",
      "{'rouge1': Score(precision=0.4642857142857143, recall=0.4148936170212766, fmeasure=0.43820224719101125), 'rouge2': Score(precision=0.08433734939759036, recall=0.07526881720430108, fmeasure=0.07954545454545454), 'rougeL': Score(precision=0.3333333333333333, recall=0.2978723404255319, fmeasure=0.3146067415730337)}\n",
      "{'rouge1': Score(precision=0.4461538461538462, recall=0.453125, fmeasure=0.4496124031007752), 'rouge2': Score(precision=0.140625, recall=0.14285714285714285, fmeasure=0.14173228346456693), 'rougeL': Score(precision=0.36923076923076925, recall=0.375, fmeasure=0.37209302325581395)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.1006927490234375,\n",
       " 'eval_bleu': 0.532010116985216,\n",
       " 'eval_rouge1': 0.475724698958912,\n",
       " 'eval_rouge2': 0.1220611863419487,\n",
       " 'eval_rougeL': 0.3661590181403348,\n",
       " 'eval_precision': 0.8116987764835357,\n",
       " 'eval_recall': 0.822573971748352,\n",
       " 'eval_f1': 0.8170644462108612,\n",
       " 'eval_runtime': 3.7447,\n",
       " 'eval_samples_per_second': 2.67,\n",
       " 'eval_steps_per_second': 0.534,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "606020b5-adfc-4623-aec0-92b37d814b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define the regex pattern to match the sentence that starts with \"everything\" and ends with \"Description:\"\n",
    "def evalInput(example):\n",
    "    # Assuming 'example' is a tuple where the first element is the input tensor\n",
    "    input_ids_tensor = example[0]\n",
    "    # Convert the tensor to a list of token IDs\n",
    "    token_ids_list = input_ids_tensor.tolist()\n",
    "    # Decode the token IDs into text\n",
    "    decoded_text = tokenizer.decode(token_ids_list, skip_special_tokens=True)\n",
    "    # Regex to capture the title and content separately\n",
    "    match = re.match(r'^Title: (.*?) Description: (.*)', decoded_text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        title = match.group(1)\n",
    "        content = match.group(2)\n",
    "        input_text = f\"Title: {title} Description: \"\n",
    "        print(input_text)\n",
    "        predictions = generate_predictions(input_text)\n",
    "        print(predictions)\n",
    "        print(compute_rouge(predictions, decoded_text))\n",
    "        bleu_scores = []\n",
    "        bert_scores = []\n",
    "        for generated_text in predictions:\n",
    "            bleu_score = sentence_bleu([decoded_text], generated_text)\n",
    "            bert_score = calculate_bertscore([generated_text], [decoded_text])\n",
    "            bleu_scores.append(bleu_score)\n",
    "            bert_scores.append(bert_score)\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "        for score in bert_scores:\n",
    "            print(score)\n",
    "            precision = precision + score['precision']\n",
    "            recall = recall + score['recall']\n",
    "            f1 = f1 + score['f1']\n",
    "        print({\n",
    "            'bleu': sum(bleu_scores) / len(bleu_scores),\n",
    "            'precision': precision / len(bert_scores),\n",
    "            'recall': recall / len(bert_scores),\n",
    "            'f1': f1 / len(bert_scores),\n",
    "        })\n",
    "        # print(\"Title:\", title)\n",
    "        # print(\"Content:\", content)\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "\n",
    "# !pip install bert-score\n",
    "import bert_score\n",
    "\n",
    "def calculate_bertscore(predictions, references, lang='en'):\n",
    "    # Calculate BERTScore\n",
    "    P, R, F1 = bert_score.score(predictions, references, lang=lang)\n",
    "    \n",
    "    # Compute average scores\n",
    "    avg_precision = P.mean().item()\n",
    "    avg_recall = R.mean().item()\n",
    "    avg_f1 = F1.mean().item()\n",
    "    \n",
    "    return {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1': avg_f1\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# predictions = [\n",
    "#     \"The cat sat on the mat.\",\n",
    "#     \"The quick brown fox jumps over the lazy dog.\"\n",
    "# ]\n",
    "# references = [\n",
    "#     \"A cat was sitting on a rug.\",\n",
    "#     \"A speedy brown fox leaps over a lazy canine.\"\n",
    "# ]\n",
    "\n",
    "# scores = calculate_bertscore(predictions, references)\n",
    "# print(scores)\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    for ref, pred in zip(references, predictions):\n",
    "        scores = scorer.score(ref, pred)\n",
    "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "    rouge1_avg = sum(rouge1_scores) / len(rouge1_scores)\n",
    "    rougeL_avg = sum(rougeL_scores) / len(rougeL_scores)\n",
    "    \n",
    "    return {\n",
    "        \"rouge1\": rouge1_avg,\n",
    "        \"rougeL\": rougeL_avg\n",
    "    }\n",
    "\n",
    "# Epoch \tTraining Loss \tValidation Loss\n",
    "# 1 \tNo log \t1.520463\n",
    "# 2 \t1.652300 \t1.467383\n",
    "# 3 \t1.393100 \t1.441400\n",
    "# 4 \t1.393100 \t1.428227\n",
    "# 5 \t1.294700 \t1.422623\n",
    "# 6 \t1.205200 \t1.425824\n",
    "# 7 \t1.140800 \t1.428631\n",
    "# 8 \t1.140800 \t1.444082\n",
    "\n",
    "# There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
    "\n",
    "# TrainOutput(global_step=2920, training_loss=1.2997734801409995, metrics={'train_runtime': 4592.453, 'train_samples_per_second': 111.226, 'train_steps_per_second': 1.987, 'total_flos': 1.5760779141316608e+16, 'train_loss': 1.2997734801409995, 'epoch': 8.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff87b09-7038-4780-a86b-f84891d14972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_predictions(input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.cuda()\n",
    "    model.eval()\n",
    "    try:\n",
    "        sample_outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            max_length=300,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7,\n",
    "            num_return_sequences=10\n",
    "        )\n",
    "        # Decode and print generated texts\n",
    "        generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in sample_outputs]\n",
    "        return generated_texts\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(\"RuntimeError during generation:\", e)\n",
    "\n",
    "        # Additional Debugging: Check logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            logits = outputs.logits\n",
    "            assert not torch.isnan(logits).any(), \"logits contain NaNs\"\n",
    "            assert not torch.isinf(logits).any(), \"logits contain Infs\"\n",
    "            print(\"Logits sample:\", logits[0, -1, :10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4655e419-5c6a-4899-8a10-6b1d18a091ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = \"Title: Sharptalon's Claw \\nDescription:\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "model.eval()\n",
    "try:\n",
    "    sample_outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        max_length=300,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        num_return_sequences=100\n",
    "    )\n",
    "    # Decode and print generated texts\n",
    "    generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in sample_outputs]\n",
    "    with open(os.path.join(output_path, 'results','output2.txt'), 'w') as file:\n",
    "        file.writelines([f\"Generated text {i+1}:\\n{text}\\n\" for i, text in enumerate(generated_texts)])\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(\"RuntimeError during generation:\", e)\n",
    "\n",
    "    # Additional Debugging: Check logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "        logits = outputs.logits\n",
    "        assert not torch.isnan(logits).any(), \"logits contain NaNs\"\n",
    "        assert not torch.isinf(logits).any(), \"logits contain Infs\"\n",
    "        print(\"Logits sample:\", logits[0, -1, :10])\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m123"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
